# FastAPI Mobile Emulator Backend & Frontend Demo

This project demonstrates a simple backend API built with FastAPI and a corresponding HTML/CSS/JS frontend designed to emulate a mobile application screen.

The primary goals are to showcase:
*   Basic user management (Register, Login, Get Info, Update) using an in-memory store.
*   Proxying requests to a Large Language Model (LLM) via the backend (specifically Ollama).
*   Real-time logging of API interactions pushed from the backend to the frontend emulator using WebSockets.
*   Serving a static frontend (HTML, CSS, JS) directly from FastAPI.
*   **Automatic Interactive API Documentation** (Swagger UI & ReDoc) generated by FastAPI.
*   Explanatory text within the frontend highlighting broader backend and software engineering concepts.

<img src="output.gif" alt="Demo" width="350">

## Features

*   **User Management:**
    *   POST `/register/`: Register a new user.
    *   POST `/login/`: Log in a user.
    *   GET `/user/{username}/`: Get basic user info.
    *   PUT `/user/{username}/`: Update user password.
    *   (Note: Uses a simple, insecure in-memory dictionary for demonstration).
*   **LLM Interaction:**
    *   POST `/llm/generate`: Takes a username and prompt, verifies the user exists (pseudo-auth), sends the prompt to an Ollama instance, and returns the generated text.
*   **Real-time Logging:**
    *   WebSocket endpoint `/ws/logs` broadcasts detailed logs of client requests, server responses, and Ollama interactions to all connected frontend clients.
*   **Automatic API Documentation:**
    *   FastAPI automatically generates interactive API documentation from your code.
    *   **Swagger UI:** Available at `/docs`. Allows you to explore and test the API endpoints directly in your browser.
    *   **ReDoc:** Available at `/redoc`. Provides an alternative documentation view.
*   **Mobile Emulator Frontend:**
    *   Simple interface served at `/` resembling a phone screen.
    *   Controls for user management and LLM interaction.
    *   Dedicated area to display real-time logs received via WebSocket.
    *   Sections explaining concepts like backend architecture, databases, auth, LLMs, WebSockets, DevOps, and security.

## Technology Stack

*   **Backend:** Python 3, FastAPI, Uvicorn
*   **API Interaction:** httpx (for calling Ollama)
*   **Real-time:** WebSockets (FastAPI integration)
*   **Frontend:** HTML, CSS, JavaScript
*   **LLM:** Ollama (running locally)
*   **API Docs:** OpenAPI, Swagger UI, ReDoc (via FastAPI)

## Prerequisites

*   **Python:** Version 3.7+ recommended.
*   **pip:** Python package installer.
*   **Ollama:**
    *   Ollama server installed and running.
    *   Ensure it's accessible at `http://localhost:11434` (Note the port **11434** used in `main.py`). You can usually start it with `ollama serve`. *If your Ollama runs on the default port 1143, you'll need to adjust the `ollama_url` in `main.py`.*
    *   A model pulled, e.g., `llama2`: `ollama pull llama2`
*   **Git:** (Optional, for cloning)

## Setup & Installation

1.  **Clone the Repository (Optional):**
    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```
    Or, simply place `main.py`, `phonemulator.html`, `style.css`, `script.js`, `requirements.txt`, and `Makefile` in the same directory.

2.  **Navigate to Project Directory:**
    ```bash
    cd /path/to/your/project/directory
    ```

3.  **Create and Activate Virtual Environment (Recommended):**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # On Windows use `.\.venv\Scripts\activate`
    ```

4.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    Or using the Makefile:
    ```bash
    make install
    ```

## Running the Application

1.  **Start Ollama Server:**
    Ensure your Ollama server is running and listening on `http://localhost:11434`. Check if you have the required model (e.g., `llama2`).
    ```bash
    ollama serve
    # (Keep this running in a separate terminal)
    ```

2.  **Run the FastAPI Backend:**
    ```bash
    uvicorn main:app --reload --host 0.0.0.0 --port 8000
    ```
    Or using the Makefile:
    ```bash
    make run
    ```
    The `--reload` flag automatically restarts the server when code changes are detected.

3.  **Access the Application & Documentation:**
    *   **Frontend Emulator:** Open your web browser to `http://localhost:8000`
    *   **Swagger UI Docs:** Navigate to `http://localhost:8000/docs`
    *   **ReDoc Docs:** Navigate to `http://localhost:8000/redoc`

## How to Use

*   Use the input fields and buttons on the main page (`/`) to interact with user management and the LLM.
*   Observe the real-time logs appearing at the bottom of the main page.
*   Explore the API endpoints in detail and test them directly using the Swagger UI (`/docs`).
*   Expand the "Broader Concepts Showcase" sections on the main page to read explanations about related technologies.

## Project Structure

```plaintext
.
├── main.py             # FastAPI application logic, API endpoints, WebSocket server
├── phonemulator.html   # Frontend HTML structure and explanatory text
├── style.css           # CSS for styling the frontend emulator
├── script.js           # Frontend JavaScript logic, API calls, WebSocket client
├── requirements.txt    # Python dependencies
├── Makefile            # Convenience commands for development
└── README.md           # This file
```

## Notes & Limitations

*   **In-Memory Database:** User data is stored in a Python dictionary and is lost when the server restarts. This is **not suitable for production**.
*   **Basic Authentication:** Login is a simple password check. No proper session management (like JWT) or password hashing is implemented.
*   **Error Handling:** Basic error handling is included, but could be more robust for production scenarios.
*   **Ollama Dependency:** The application requires a running Ollama instance configured as specified.

## AI Assistance Acknowledgement

Significant portions of the code and documentation in this project (including file structures, function logic, this README) were generated with the assistance of large language models (e.g., Google Gemini).

AI was used as a tool for:
*   Generating initial code based on prompts.
*   Assisting with boilerplate code writing.
*   Providing suggestions for logic and implementation.
*   Generating documentation drafts.

All AI-generated code was reviewed, tested, and modified by the developer.